{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jtn5k6uWfUFM"
   },
   "source": [
    "# Практическое задание 4. EM-алгоритм"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XcI_9od5fUFO"
   },
   "source": [
    "# Generative model of Labels, Abilities, and Difficulties (GLAD)\n",
    "\n",
    "Мы рассмотрели задачу восстановления истинной разметки по меткам от экспертов (которым мы не можем доверять в полной мере, более того, их предсказания могут расходиться).\n",
    "\n",
    "Рассмотрим следующую вероятностную модель:\n",
    "\n",
    "$$ p(L, Z | \\alpha, \\beta) = \\prod_{i=1}^{n} \\prod_{j=1}^m \\sigma(\\alpha_j\\beta_i)^{[l_{ij}=z_i]}\\sigma(-\\alpha_j\\beta_i)^{1-[l_{ij}=z_i]} p(z_j)$$\n",
    "\n",
    "где $l_{ij} -$ ответ $j$-го эксперта на задачу $i$, $z_j -$ истинная разметка, $\\alpha_i, \\beta_j-$ уровень экспертизы и сложность задачи соответственно. Для более подробного описания модели можно прочитать [оригинальную статью](http://papers.nips.cc/paper/3644-whose-vote-should-count-more-optimal-integration-of-labels-from-labelers-of-unknown-expertise.pdf). Априорное распределение положим равномерным: $p(z_i) = 0.5$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "72lw2421fUFP"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "seed = 0xDEADF00D\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "g5zRN3rvfUFQ"
   },
   "outputs": [],
   "source": [
    "L = np.load('L.npy')\n",
    "n, m = L.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Nm94lL8sv7hi",
    "outputId": "25f5de4b-c0a6-4496-b9d2-834b20c50b6e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10, 10, 10, 10])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.tile(np.arange(5), (4, 1)).sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Na7cItnovPkU"
   },
   "source": [
    "## Задание 1. Реализуйте EM-алгоритм для заданной выше модели. Вы можете воспользоваться предложенными шаблонами или написать свои."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bqwqw_EQfUFQ"
   },
   "source": [
    "**Задание 1.  Реализуйте EM-алгоритм для заданной выше модели. Вы можете воспользоваться предложенными шаблонами или написать свои.\n",
    "\n",
    "Обратите внимание, что правдоподобие моделирует не вероятность метки $l_{ij}$ принять значение 1 или 0, а вероятность того, что она равна скрытой переменной $z_i$, т.е. $p(l_{ij} = z_j|z_j, \\alpha_j, \\beta_i) \\neq p(l_{ij} = 1|\\alpha_j, \\beta_i) $. При этом какая из скрытых переменных соответствует метке 1, заранее неизвестно. Не забывайте, что параметры $\\beta_i$ должны быть неотрицательными, для этого оптимизируйте $\\log \\beta$.\n",
    "\n",
    "Также при работе с вероятностями не забывайте о точности:\n",
    "1. Используйте логарифмы вероятностей.\n",
    "2. $\\log \\sigma(a)$ лучше преобразовать в $\\log \\sigma(a) = -\\log(1 + \\exp(-a)) = -\\mathrm{softplus}(-a) $\n",
    "3. Ещё полезные функции: `scipy.special.expit`, `scipy.special.logsumexp`, `np.log1p`\n",
    "\n",
    "Для отладки может быть полезно проверить градиент с помощью `scipy.optimize.check_grad`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "iwuj-UM6xOh6"
   },
   "outputs": [],
   "source": [
    "from scipy.special import expit, logsumexp, softmax\n",
    "from scipy.optimize import check_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "aPtozb-MfUFQ"
   },
   "outputs": [],
   "source": [
    "def softplus(x):\n",
    "    '''stable version of log(1 + exp(x))'''\n",
    "    c = (x > 20) * 1.\n",
    "    return np.log1p(np.exp(x * (1-c)) * (1-c)) + x * c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "9IkOwrGofUFQ"
   },
   "outputs": [],
   "source": [
    "def likelihood(alpha, beta):\n",
    "    \"\"\" p(l=z|z, \\alpha, \\beta) for z_0, z_1\n",
    "    Args:\n",
    "        alpha: ndarray of shape (n_experts).\n",
    "        beta: ndarray of shape (n_problems).\n",
    "    \"\"\"\n",
    "    outer_product = np.outer(beta, alpha)\n",
    "    return expit(outer_product), expit(-outer_product)\n",
    "\n",
    "\n",
    "def log_likelihood(alpha, beta):\n",
    "    \"\"\" log p(l=z|z, \\alpha, \\beta) for z_0, z_1\n",
    "    Args:\n",
    "        alpha: ndarray of shape (n_experts).\n",
    "        beta: ndarray of shape (n_problems).\n",
    "    \"\"\"\n",
    "    outer_product = np.outer(beta, alpha)\n",
    "    return -softplus(-outer_product), -softplus(outer_product)\n",
    "\n",
    "def log_posterior_sum_term(alpha, beta, L):\n",
    "    \"\"\" Log-posterior - without p(z) term: log p(z|l, \\alpha, \\beta) - log p(z)\n",
    "    Args:\n",
    "        alpha: ndarray of shape (n_experts).\n",
    "        beta: ndarray of shape (n_problems).\n",
    "        L: ndarray of shape (n_problems, n_experts).\n",
    "    \"\"\"\n",
    "    log_sigmoid_pos, log_sigmoid_neg = log_likelihood(alpha, beta)\n",
    "\n",
    "    zeros_hits = (L == 0)\n",
    "    ones_hits = 1 - zeros_hits\n",
    "\n",
    "    zeros_log_likelihood = np.sum(zeros_hits * log_sigmoid_pos + ones_hits * log_sigmoid_neg, axis=1)\n",
    "    ones_log_likelihood = np.sum(ones_hits * log_sigmoid_pos + zeros_hits * log_sigmoid_neg, axis=1)\n",
    "\n",
    "    return zeros_log_likelihood, ones_log_likelihood\n",
    "\n",
    "\n",
    "def log_posterior(alpha, beta, L):\n",
    "    \"\"\" Log-posterior: log p(z|l, \\alpha, \\beta)\n",
    "    Args:\n",
    "        alpha: ndarray of shape (n_experts).\n",
    "        beta: ndarray of shape (n_problems).\n",
    "        L: ndarray of shape (n_problems, n_experts).\n",
    "    \"\"\"\n",
    "    p_0 = 0.5\n",
    "    p_1 = 1 - p_0\n",
    "\n",
    "    zeros_log_likelihood, ones_log_likelihood = log_posterior_sum_term(alpha, beta, L)\n",
    "    return np.log(p_0) + zeros_log_likelihood, np.log(p_1) + ones_log_likelihood\n",
    "\n",
    "\n",
    "def posterior(alpha, beta, L):\n",
    "    \"\"\" Posterior: p(z|l, \\alpha, \\beta), having shape (2, n_problems)\n",
    "    Args:\n",
    "        alpha: ndarray of shape (n_experts).\n",
    "        beta: ndarray of shape (n_problems).\n",
    "        L: ndarray of shape (n_problems, n_experts).\n",
    "    \"\"\"\n",
    "\n",
    "    q_log_zeros, q_log_ones = log_posterior(alpha, beta, L)\n",
    "    q_zeros, q_ones = np.exp(q_log_zeros), np.exp(q_log_ones)\n",
    "    prior = q_zeros + q_ones\n",
    "\n",
    "    q = np.vstack([q_zeros / prior, q_ones / prior])\n",
    "\n",
    "    assert q.shape == (2, L.shape[0]), q.shape\n",
    "    return q\n",
    "\n",
    "\n",
    "def grad_lb(alpha, beta, L, q):\n",
    "    \"\"\" Gradient of lower bound wrt alpha, wrt logbeta\n",
    "    Args:\n",
    "        alpha: ndarray of shape (n_experts).\n",
    "        beta: ndarray of shape (n_problems).\n",
    "        L: ndarray of shape (n_problems, n_experts).\n",
    "        q: ndarray of shape (2, n_problems).\n",
    "    \"\"\"\n",
    "    log_sigmoid_pos, log_sigmoid_neg = likelihood(alpha, beta)\n",
    "\n",
    "    zeros_hits = (L == 0)\n",
    "    ones_hits = 1 - zeros_hits\n",
    "\n",
    "    zeros_sum_term = zeros_hits * log_sigmoid_neg - ones_hits * log_sigmoid_pos\n",
    "    ones_sum_term = ones_hits * log_sigmoid_neg - zeros_hits * log_sigmoid_pos\n",
    "\n",
    "    grad_alpha = ((q[0, :] * beta) @ zeros_sum_term + (q[1, :] * beta) @ ones_sum_term).T\n",
    "    grad_beta = (q[0, :].T * (zeros_sum_term @ alpha) + q[1, :].T * (ones_sum_term @ alpha)).T\n",
    "    grad_logbeta = grad_beta * beta\n",
    "\n",
    "    return grad_alpha, grad_logbeta\n",
    "\n",
    "\n",
    "def lower_bound(alpha, beta, L, q):\n",
    "    \"\"\" Lower bound\n",
    "    Args:\n",
    "        alpha: ndarray of shape (n_experts).\n",
    "        beta: ndarray of shape (n_problems).\n",
    "        L: ndarray of shape (n_problems, n_experts).\n",
    "        q: ndarray of shape (2, n_problems).\n",
    "    \"\"\"\n",
    "    log_sigmoid_pos, log_sigmoid_neg = log_likelihood(alpha, beta)\n",
    "\n",
    "    zeros_hits = (L == 0)\n",
    "    ones_hits = 1 - zeros_hits\n",
    "\n",
    "    log_likelihood_term = np.vstack([\n",
    "        np.sum(zeros_hits * log_sigmoid_pos + ones_hits * log_sigmoid_neg, axis=1),\n",
    "        np.sum(ones_hits * log_sigmoid_pos + zeros_hits * log_sigmoid_neg, axis=1)\n",
    "    ])\n",
    "\n",
    "    return np.sum(log_likelihood_term * q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "42BLq3bifUFQ"
   },
   "outputs": [],
   "source": [
    "def em(L, n_steps=1000, lr=1e-3):\n",
    "    alpha, logbeta = np.random.randn(m), np.random.randn(n)\n",
    "    q = np.ones((2, len(logbeta))) * 0.5\n",
    "\n",
    "    for step in range(n_steps):\n",
    "        q = posterior(alpha=alpha, beta=np.exp(logbeta), L=L)\n",
    "\n",
    "        grad_alpha, grad_logbeta = grad_lb(alpha=alpha, beta=np.exp(logbeta), L=L, q=q)\n",
    "        alpha, logbeta = alpha + lr * grad_alpha, logbeta + lr * grad_logbeta\n",
    "\n",
    "    return alpha, np.exp(logbeta), q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "PKkWfCfqfUFQ"
   },
   "outputs": [],
   "source": [
    "alpha, beta, q = em(L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qo9ZTBlVwTz7",
    "outputId": "80b41a23-28f4-4fec-f0fc-019a6b9acae0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.63753547,  0.75228005,  4.4001252 ,  0.54804297,  0.64690295,\n",
       "        4.35564589,  0.63207995,  4.04474391, -4.22843341,  0.6570759 ,\n",
       "       -4.3909037 , -4.31143788,  4.2226915 ,  0.55409814,  0.64945446,\n",
       "        0.53662284,  0.64960411,  4.12157083, -4.06185601,  4.04695979])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vLvOicGEwXoT",
    "outputId": "dd617818-5f3b-4802-b633-970216214973"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.16625135, 1.48023189, 1.98869631, ..., 0.30868682, 1.06586015,\n",
       "       1.45007776])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fkEwDqf4xbw6",
    "outputId": "7d952bf6-1812-4da8-8dbf-5ab7d3d73c03"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.07783667e-23, 2.21312174e-29, 2.64051799e-40, ...,\n",
       "        7.50239486e-04, 1.00000000e+00, 1.00000000e+00],\n",
       "       [1.00000000e+00, 1.00000000e+00, 1.00000000e+00, ...,\n",
       "        9.99249761e-01, 1.15117049e-20, 9.02839383e-29]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RASpxo-uxmtG",
    "outputId": "1fa9c18a-17a7-4123-b4ec-b7a2c9f98aeb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-14669.570548477524"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lower_bound(alpha, beta, L, q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tf7bRSaAfUFR"
   },
   "source": [
    "## Задание 2. Загрузите настоящую разметку. Посчитайте `accuracy` разметки, полученной с помощью обычного голосования по большинству среди экспертов, и сравните его с качеством, полученным с помощью EM-алгоритма.\n",
    "Помните, что алгоритму не важно, какая метка 0, а какая 1, поэтому если получите качество <0.5, то просто поменяйте метки классов (не забудьте также поменять знак у $\\alpha$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "elbbZJkQx1KY"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "uGfb_T3DfUFR"
   },
   "outputs": [],
   "source": [
    "y = np.load('y.npy')\n",
    "# (∩ ￣ー￣)⊃ ✳✨✳✨✳✨✳"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e-7j6cvox9Eb",
    "outputId": "34894378-e1cc-4af1-aa11-c80bdb49840e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting accuracy: 0.904\n",
      "EM accuracy: 0.9555\n"
     ]
    }
   ],
   "source": [
    "voting_predicts = (np.sign(np.sum(L - 0.5, axis=1)) + 1) // 2\n",
    "voting_accuracy = accuracy_score(voting_predicts, y)\n",
    "print(f'Voting accuracy: {voting_accuracy}')\n",
    "\n",
    "em_predicts = np.argmax(q, axis=0)\n",
    "em_accuracy = accuracy_score(em_predicts, y)\n",
    "if em_accuracy < 0.5:\n",
    "    em_accuracy = accuracy_score(1 - em_predicts, y)\n",
    "print(f'EM accuracy: {em_accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kD3LGppOfUFR"
   },
   "source": [
    "## Задание 3.  Попробуйте проинтерпретировать полученные коэфициенты $\\alpha$.\n",
    "Есть ли в выборке эксперты, которые намеренно голосуют неверно? Как это можно понять по альфам? Продемонстрируйте, что эксперты действительно чаще голосуют за неверный класс. Постройте график зависимости доли врено размеченных экспертом объектов от коэффициента $\\alpha$. Прокомментируйте результаты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "0W_6VxGJyIDV"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "LW-7utXkfUFR"
   },
   "outputs": [],
   "source": [
    "expert_accuracies = [accuracy_score(L[:, i], y) for i in range(L.shape[1])]\n",
    "# (∩ᄑ_ᄑ)⊃━☆ﾟ*･｡*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 529
    },
    "id": "RmfjNA_wyYFO",
    "outputId": "1d22a142-867a-4912-d545-c90ff6ca1202"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.relplot(y=expert_accuracies, x=alpha)\n",
    "plt.xlabel('alpha')\n",
    "plt.ylabel('expert accuracy')\n",
    "plt.title('Expert accuracies w.r.t. corresponding alphas')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SuEeiVdJfUFR"
   },
   "source": [
    "## Задание 4. Как уже было замечено выше, модели не важно, какой класс 1, а какой 0. Скажем, если все эксперты оказались максимально противными и ставят метку с точностью наоборот, то у вас будет полная согласованность между экспертами, при этом невозможно понять правильно они разметили выборку или нет, смотря только на такую разметку. Чтобы избежать этого, можно включать в выборку вопрос с заведомо известным ответом, тогда вы сможете определить, ставит ли эксперт специально неверные метки.\n",
    "\n",
    "Чтобы обощить данную модель на случай заданий с заведомо известной меткой, достоточно не делать для них E-шаг, а всегда полагать апостериорное распределение вырожденным в истинном классе. Реализуйте данную модель и используйте истинную разметку *для нескольких* задач из обучения. Проинтерпретируйте полученные результаты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "VSaaEHAgyzq1"
   },
   "outputs": [],
   "source": [
    "def em_with_known_answers(L, n_steps=1000, lr=1e-3, known_indices=None, known_labels=None):\n",
    "    # initialize parameters\n",
    "    alpha, logbeta = np.random.randn(m), np.random.randn(n)\n",
    "    q = np.ones((2, len(logbeta))) * 0.5\n",
    "    q[0, known_indices] = 1 - known_labels\n",
    "    q[1, known_indices] = known_labels\n",
    "\n",
    "    unknown_indices = np.delete(np.arange(L.shape[0]), known_indices)\n",
    "    L_unknown = L[unknown_indices, :]\n",
    "\n",
    "    for step in range(n_steps):\n",
    "        beta_unknown = np.exp(logbeta)[unknown_indices]\n",
    "        q[:, unknown_indices] = posterior(alpha=alpha, beta=beta_unknown, L=L_unknown)\n",
    "\n",
    "        grad_alpha, grad_logbeta = grad_lb(alpha=alpha, beta=np.exp(logbeta), L=L, q=q)\n",
    "        alpha, logbeta = alpha + lr * grad_alpha, logbeta + lr * grad_logbeta\n",
    "\n",
    "    return alpha, np.exp(logbeta), q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qSd1LLHay2Z8",
    "outputId": "c96422ae-4dcc-46c3-f004-94ae18b9ea97"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting accuracy: 0.904\n"
     ]
    }
   ],
   "source": [
    "voting_predicts = (np.sign(np.sum(L - 0.5, axis=1)) + 1) // 2\n",
    "voting_accuracy = accuracy_score(voting_predicts, y)\n",
    "print(f'Voting accuracy: {voting_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fAkjsGetzBT4",
    "outputId": "2a4fa33a-d611-4bb4-c2da-79d956458b46"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EM accuracy with 0 known answers: 0.9555\n",
      "EM accuracy with 100 known answers: 0.9585\n",
      "EM accuracy with 200 known answers: 0.8595\n",
      "EM accuracy with 400 known answers: 0.764\n",
      "EM accuracy with 800 known answers: 0.9735\n",
      "EM accuracy with 1600 known answers: 0.9915\n"
     ]
    }
   ],
   "source": [
    "known_counts = [0, 100, 200, 400, 800, 1600]\n",
    "\n",
    "for known_count in known_counts:\n",
    "    alpha, beta, q = em_with_known_answers(\n",
    "        L, n_steps=1000, lr=1e-3,\n",
    "        known_indices=np.arange(known_count), known_labels=y[:known_count]\n",
    "    )\n",
    "    em_predicts = np.argmax(q, axis=0)\n",
    "    em_accuracy = accuracy_score(em_predicts, y)\n",
    "    if em_accuracy < 0.5:\n",
    "        em_accuracy = accuracy_score(1 - em_predicts, y)\n",
    "\n",
    "    print(f'EM accuracy with {known_count} known answers: {em_accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rTpG-eVhfUFR"
   },
   "source": [
    "# Выравнивание слов (Word Alignment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K-mCAChlfUFS"
   },
   "source": [
    "EM-алгоритм также применяют на практике для настройки параметров модели выравнивания слов, более сложные модификации которой используются в статистическом машинном переводе. Мы не будем подробно обсуждать применение word alignment для перевода и ограничимся следующей целью: пусть у нас есть параллельный корпус из предложений на исходном языке и их переводов на целевой язык (в этом задании используются английский и чешский соответственно).\n",
    "\n",
    "Первая задача — определить с помощью этого корпуса, как переводится каждое отдельное слово на целевом языке. Вторая задача — для произвольной пары из предложения и его перевода установить, переводом какого слова в исходном предложении является каждое слово в целевом предложении. Оказывается, у обеих задач существует элегантное и эффективное решение при введении правильной вероятностной модели: в этой части задания вам предстоит его реализовать и оценить результаты работы. Но обо всём по порядку :)\n",
    "\n",
    "---\n",
    "\n",
    "Перед тем, как заниматься машинным обучением, давайте разберёмся с данными и метриками в интересующей нас задаче. В ячейке ниже загружается и разархивируется параллельный английско-чешский корпус, в котором есть разметка выравнивания слов. Нетрудно заметить, что формат XML-файла, использованный его авторами, не вполне стандартный: нет готовой команды , которая позволила бы получить список пар предложений вместе с выравниваниями. Это значит, что нужно разобраться с форматом и написать парсер самостоятельно, используя встроенные средства Python, например, модуль [xml](https://docs.python.org/3.7/library/xml.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dJ-PoXBPfUFS"
   },
   "source": [
    "## Задание -2.  Реализуйте функцию `extract_sentences`, которая принимает на вход путь к файлу с XML-разметкой, используемой в этом датасете, и возвращает список параллельных предложений, а также список из «уверенных» (sure) и «возможных» (possible) пар выравниваний. Отправьте вашу реализацию в Яндекс.Контест, чтобы убедиться в её корректности; в следующей ячейке ноутбука соберите все пары размеченных предложений из датасета в два списка `all_sentences` (список `SentencePair`) и `all_targets` (список LabeledAlignment).\n",
    "\n",
    "Здесь и далее соблюдайте сигнатуры функций и пользуйтесь объявленными в модуле `preprocessing.py` классами для организации данных. Стоит заметить, что предложения уже токенизированы (даже отделена пунктуация), поэтому предобработку текстов совершать не нужно. Обратите внимание на формат хранения выравниваний: нумерация начинается с 1 (в таком виде и нужно сохранять), первым в паре идёт слово из англоязычного предложения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "FAnfMN3YfUFS"
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "from preprocessing import extract_sentences\n",
    "\n",
    "all_sentences = []\n",
    "all_targets = []\n",
    "# (´◕▽◕)⊃━☆"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_files = glob.glob(\"path\")\n",
    "\n",
    "for file_path in data_files:\n",
    "    sentences, targets = extract_sentences(file_path)\n",
    "    all_sentences.extend(sentences)\n",
    "    all_targets.extend(targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D9eWzphUfUFT"
   },
   "source": [
    "## Задание -1.  Реализуйте функции `get_token_to_index` и `tokenize_sents` из модуля `preprocessing.py`, постройте словари token->index для обоих языков и постройте список из `TokenizedSentencePair` по выборке. Реализации функций также отправьте в Яндекс.Контест."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing import get_token_to_index, tokenize_sents\n",
    "\n",
    "t_idx_src, t_idx_tgt = get_token_to_index(all_sentences)\n",
    "tokenized_sentences = tokenize_sents(all_sentences, t_idx_src, t_idx_tgt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iGXL8414fUFT"
   },
   "source": [
    "В качестве бейзлайна для этой задачи мы возьмём способ выравнивания слов по коэффициенту Дайса: слово в исходном языке является переводом слова на целевом языке, если они часто встречаются в одних и тех же предложениях и редко встречаются по отдельности.\n",
    "\n",
    "Математически это записывается по аналогии с мерой Жаккара: пусть $c(x,y)$ — число параллельных предложений, в которых есть и $x$ (на исходном языке), и $y$ (на целевом языке), а $c(x)$ и $c(y)$ — суммарное количество предложений, в которых встречается слово $x$ и $y$ соответственно. Тогда $\\textrm{Dice}(x,y)=\\frac{2 \\cdot c(x,y)}{c(x) + c(y)}$ — характеристика «похожести» слов $x$ и $y$. Она равна 1, если слова встречаются только в контексте друг друга (не бывает предложений только со словом $x$ без $y$ в переводе и наоборот), равна 0, если слова никогда не встречаются в параллельных предложениях и находится между пороговыми значениями в остальных случаях.\n",
    "\n",
    "В файле `models.py` описан абстрактный класс `BaseAligner`, наследником которого должны являться все модели в задании, а также приведён пример реализации `DiceAligner` выравнивания слов описанным выше путём. Ниже вы можете увидеть, как применять эту модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import DiceAligner\n",
    "\n",
    "baseline = DiceAligner(len(t_idx_src), len(t_idx_tgt), threshold=0.01)\n",
    "baseline.fit(tokenized_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mUn31pi2fUFT"
   },
   "source": [
    "Чтобы оценить качество модели выравнивания, пользуясь имеющейся разметкой, существует ряд автоматических метрик. Они подразумевают, что в разметке есть два вида выравниваний — «уверенные» (sure) и «возможные» (possible). Обозначим для конкретного предложения первое множество выравниваний $S$, второе — $P$, а предсказанные выравнивания — $A$; причём, в отличие от разметки в файле, $S\\subseteq P$. Тогда можно предложить три метрики, используя только операции над этими множествами:\n",
    "\n",
    "Precision $=\\frac{|A\\cap P|}{|A|}$. Отражает, какая доля предсказанных нами выравниваний вообще корректна; если мы дадим в качестве ответа все возможные пары слов в предложении, эта метрика сильно просядет.\n",
    "\n",
    "Recall $=\\frac{|A\\cap S|}{|S|}$. Эта метрика показывает, какую долю «уверенных» выравниваний мы обнаружили. Если мы попытаемся сделать слишком консервативную модель, которая выдаёт 0 или 1 предсказание на нетривиальных предложениях, полнота получится крайне низкая.\n",
    "\n",
    "Alignment Error Rate (AER) $=1-\\frac{|A\\cap P|+|A\\cap S|}{|A|+|S|}$. Метрика является комбинацией двух предыдущих и отслеживает общее качество работы системы, штрафуя оба описанных выше вида нежелаемого поведения модели.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZyyTBrDO-3VZ"
   },
   "source": [
    "## Задание 0.  Реализуйте функции compute_precision, compute_recall, compute_aer из модуля quality.py. Оцените качество бейзлайнового метода. Обратите внимание, что нужно использовать микро-усреднение во всех функциях: необходимо просуммировать числитель и знаменатель по всем предложениям и только потом делить."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from quality import compute_aer\n",
    "\n",
    "compute_aer(all_targets,baseline.align(tokenized_sentences))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-8SKJt-WfUFT"
   },
   "source": [
    "Теперь мы можем перейти к базовой вероятностной модели для выравнивания слов. Пусть $S=(s_1,\\ldots,s_n)$ исходное предложение, $T=(t_1,\\ldots,t_m)$ — его перевод. В роли латентных переменных будут выступать выравнивания $A=(a_1,\\ldots,a_m)$ каждого слова в целевом предложении, причём $a_i\\in\\{1,\\ldots,n\\}$ (считаем, что каждое слово в $t$ является переводом какого-то слова из $s$). Параметрами модели является матрица условных вероятностей перевода: каждый её элемент $\\theta(y|x)=p(y|x)$ отражает вероятность того, что переводом слова $x$ с исходного языка на целевой является слово $y$ (нормировка, соответственно, совершается по словарю целевого языка). Правдоподобие латентных переменных и предложения на целевом языке в этой модели записывается так:\n",
    "\n",
    "$$\n",
    "p(A,T|S)=\\prod_{i=1}^m p(a_i)p(t_i|a_i,S)=\\prod_{i=1}^m \\frac{1}{n}\\theta(t_i|s_{a_i}).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z7F8BsnKfUFT"
   },
   "source": [
    "## Задание 1. Выведите шаги EM-алгоритма для этой модели, а также получите выражение для подсчёта нижней оценки правдоподобия ($\\mathcal{L}$ в обозначениях лекции и семинара). Обратите внимание, что на M-шаге нужно найти аналитический максимум по параметрам."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "io3xcxX1fUFT"
   },
   "source": [
    "(∩｀-´)⊃━☆ﾟ.*･｡ﾟ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "06X66tQ0fUFT"
   },
   "source": [
    "## Задание 2.  Реализуйте все методы класса `WordAligner` в соответствии с полученными вами формулами. Протестируйте вашу реализацию через Яндекс.Контест, а здесь обучите модель и посчитайте её AER на истинной разметке. Чтобы предсказать выравнивание для пары предложений в этой модели, следует выбирать в соответствие для слова в целевом предложении с индексом $i$ позицию, соответствующую максимуму апостериорного распределения $p(a_i|T,S)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import WordAligner\n",
    "\n",
    "word_aligner = WordAligner(len(t_idx_src), len(t_idx_tgt), 20)\n",
    "word_aligner.fit(tokenized_sentences);\n",
    "\n",
    "# ༼つ ಠ益ಠ༽つ ─=≡ΣO))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5U-m7NhAfUFU"
   },
   "source": [
    "Заметим, что таблицу вероятностей перевода можно использовать и саму по себе для построения словарей. Пример работы показан ниже: метод хоть и работает, но мягко говоря, неидально — слишком мало данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kxYbmgVofUFU"
   },
   "outputs": [],
   "source": [
    "idx_token_tgt = {index:token for token, index in t_idx_tgt.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Dm6YbNeFfUFU"
   },
   "outputs": [],
   "source": [
    "[idx_token_tgt[i] for i in word_aligner.translation_probs[t_idx_src['Mr']].argsort()[-3:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2LdcUl68fUFU"
   },
   "outputs": [],
   "source": [
    "[idx_token_tgt[i] for i in word_aligner.translation_probs[t_idx_src['Mrs']].argsort()[-3:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ewozHujQfUFU",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "[idx_token_tgt[i] for i in word_aligner.translation_probs[t_idx_src['water']].argsort()[-3:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0k8BsTVhfUFU"
   },
   "outputs": [],
   "source": [
    "[idx_token_tgt[i] for i in word_aligner.translation_probs[t_idx_src['depended']].argsort()[-3:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UD4JZAZtfUFU"
   },
   "outputs": [],
   "source": [
    "[idx_token_tgt[i] for i in word_aligner.translation_probs[t_idx_src['on']].argsort()[-3:]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g_7-yT1MfUFV"
   },
   "source": [
    "## Задание 3. Мы смогли получить матрицу условных вероятностей перевода исходного языка в целевой. Можно ли, пользуясь этой матрицей и ещё какими-то статистиками по параллельному корпусу, получить вероятности перевода целевого языка в исходный? Реализуйте такой метод и приведите ниже пример его работы, показав пару удачных переводов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mbxYb6DufUFV"
   },
   "outputs": [],
   "source": [
    "# (>ω<)ノ—==ΞΞ☆*✲ﾟ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m8TqxYRkfUFc"
   },
   "source": [
    "## Задание 4.  Визуализируйте полученные выравнивания для нескольких предложений в виде heatmap: по одной из осей располагаются токены исходного текста, по другой — токены его перевода, на пересечении позиций $i$ и $j$ — 0 либо 1 в зависимости от того, является ли в обученной модели $a_i$ равным $j$. Можете ли вы их проинтерпретировать? Постройте аналогичный график, но без дискретизации, а визуализируя напрямую апостериорное распределение. Можете ли вы найти ситуации, в которых модель не уверена, переводом какого слова является слово $i$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "etyWzZDHfUFc"
   },
   "outputs": [],
   "source": [
    "# (•̀ 3 •́)━★☆.*･｡ﾟ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QM8nBoy3fUFc"
   },
   "source": [
    "Заметим, что при задании модели мы сделали довольно сильное предположение о том, что вероятности выбора слова для выравнивания никак не зависят от позиции слова в целевом предложении. Можно сделать эти вероятности настраиваемыми параметрами, получив прямоугольную матрицу $\\phi_{m,n}(j|i)=p(a_i=j|m,n)$ для каждой пары длин предложений $m,n$: по-прежнему мы получаем распределение над индексами в исходном предложении. Тогда модель приобретает вид\n",
    "$$\n",
    "p(A,T|S)=\\prod_{i=1}^m p(a_i|m,n)p(t_i| a_i, S)=\\prod_{i=1}^m \\phi_{m,n}(a_i|i)\\theta(t_i|s_{a_i}).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0SB_jngbfUFc"
   },
   "source": [
    "**Задание 5.  Выведите шаги EM-алгоритма для этой модели, а также получите выражение для подсчёта нижней оценки правдоподобия."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BpiVEaITfUFc"
   },
   "source": [
    "ଘ(๑˃̵ᴗ˂̵)━☆ﾟ.*･｡ﾟ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gT6rN01gfUFc"
   },
   "source": [
    "## Задание 6.Реализуйте все методы класса `WordPositionAligner`, протестируйте их корректность. Обучите модель, оцените её качество на истинной разметке и сравните его с качеством предыдущей более простой модели. Проиллюстрируйте влияние стартовых параметров на результат, проинициализировав эту модель параметрами модели из задания 2 (важно, чтобы суммарное число эпох обучения в обоих сценариях оставалось тем же)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DKHaDL4FfUFe"
   },
   "outputs": [],
   "source": [
    "from models import WordPositionAligner\n",
    "# (≧ ◡ ≦)━★☆.*･｡ﾟ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CdJ8lwNwfUFe"
   },
   "source": [
    "## Задание 7.\n",
    "\n",
    "Улучшите качество получившейся системы настолько, насколько сможете. За каждые 5 процентов, на которые AER на тех же данных получается меньше, чем минимум ошибки всех предыдущих моделей, вы получите по 1 бонусному баллу.\n",
    "\n",
    "Ниже приведены несколько идей, которые могут помочь вам повысить\n",
    "\n",
    "* Модифицировать модель: как вы можете понять, недостатком второго реализованного вами подхода является избыточное число параметров из-за необходимости подерживать отдельную матрицу для каждой различной пары длин предложений в корпусе. В статье https://www.aclweb.org/anthology/N13-1073.pdf приведён способ снижения числа параметров, задающих априорное распределение позиций выравнивания, который позволяет в десять раз быстрее обучать модель и получать лучшее качество.\n",
    "* Предобработка текстов: мы никак не заостряли внимание на этом шаге, но сейчас токенизация чувствительна к регистру, а слова на чешском языке вдобавок обладают богатой морфологией и большим количеством диакритических знаков. Если сократить количество параметров модели (различных слов), можно ускорить обучение и добиться лучших результатов, потому что статистики по словам будут считаться по большему числу параллельных предложений.\n",
    "* Агрегация по двум направлениям: в статье https://www.aclweb.org/anthology/J03-1002/ утверждается, что асимметричность выравниваний вредит качеству, потому что из-за выбранной модели одному слову в целевом предложении не может соответствовать два слова в исходном предложении. Для решения этой проблемы (и улучшения метрик, разумеется) авторы предлагают несколько алгоритмов, которые можно попробовать применить в этом задании.\n",
    "* Использовать больше обучающих данных. В корпусе, которым мы пользуемся, только пара тысяч предложений, чего может не хватать для по-настоящему хорошей модели выравнивания. Разумеется, неразмеченных параллельных английско-чешских корпусов гораздо больше, поэтому можно воспользоваться ими. Хорошая точка для старта — данные с соревнования по машинному переводу  [воркшопа WMT](http://www.statmt.org/wmt20/translation-task.html).\n",
    "* В языках часто существуют слова наподобие артиклей или предлогов, которым не соответствует ни одно слово в переводе. Все рассмотренные в рамках задания модели это не учитывают, возможно, добавление возможности перевода в «нулевой» токен улучшит качество модели (при тестировании такие выравнивания имеет смысл выбрасывать)\n",
    "\n",
    "Если вы захотите улучшить качество модели путём улучшения предобработки или добавления данных, помните, что оно не должно приводить к удалению предложений из тестовых данных из-за отсутствия слов в построенном словаре. Если такое всё же произошло, для корректности сравнения считайте AER вашей модели на удалённых предложениях равным 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gzS0TazCfUFe"
   },
   "outputs": [],
   "source": [
    "# ┐_(ツ)_┌━☆ﾟ.*･｡ﾟ"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
